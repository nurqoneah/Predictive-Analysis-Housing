# -*- coding: utf-8 -*-
"""Housing Price Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vY-q7tGjq3euJO5BryvPPv2r2DgzhhV8

# **Proyek Pertama : Predictive Analytics**


### **Nama : Nurul Nyi Qoniah**
### **Email : nurulqoniah313@gmail.com**
### **Username : nurqoneah**

## **Deskripsi**
Membuat model predictive analytics (housing price prediction) menggunakan dataset dari Kaggle [Housing Dataset](https://www.kaggle.com/code/abdelrahmanramadan2/housing-price-prediction-using-linear-regression)

## **Business Understanding**
Untuk mengoptimalkan keuntungan perusahaan, dibutuhkan satu keputusan untuk menentukan harga jual rumah yang sesuai. Perusahaan memiliki dataset harga properti rumah untuk membantu perusahaan dalam menentukan harga jual yang sesuai berdasarkan faktor-faktor seperti area, kamar tidur, dan lain-laini.

## **Data Understanding**

Dataset [Housing Dataset](https://www.kaggle.com/code/abdelrahmanramadan2/housing-price-prediction-using-linear-regression) memiliki 13 fitur dan 545 record data harga untuk setiap rumahnya. Kesemua feature dapat digunakan untuk memprediksi harga rumah yang sesuai.

## **Data Loading**

### **Import library**
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

"""### **Load Dataset**"""

df = pd.read_csv("/content/Housing.csv")
df.head()

"""## **Exploratory Data Analysis**"""

df.shape

df.describe()

df.info()

"""## **Menangani Missing Value**"""

df.isnull().sum()

"""## **Menangani Outliers**"""

fig, axs = plt.subplots(2,3, figsize = (10,5))
plt1 = sns.boxplot(df['price'], ax = axs[0,0])
plt2 = sns.boxplot(df['area'], ax = axs[0,1])
plt3 = sns.boxplot(df['bedrooms'], ax = axs[0,2])
plt1 = sns.boxplot(df['bathrooms'], ax = axs[1,0])
plt2 = sns.boxplot(df['stories'], ax = axs[1,1])
plt3 = sns.boxplot(df['parking'], ax = axs[1,2])

plt.tight_layout()



Q1 = df.price.quantile(0.25)
Q3 = df.price.quantile(0.75)
IQR=Q3-Q1
df = df[(df.price >= Q1 - 1.5*IQR) & (df.price <= Q3 + 1.5*IQR)]

# Cek ukuran dataset setelah kita drop outliers price
df.shape

Q1 = df.area.quantile(0.25)
Q3 = df.area.quantile(0.75)
IQR=Q3-Q1
df = df[(df.area >= Q1 - 1.5*IQR) & (df.area <= Q3 + 1.5*IQR)]

# Cek ukuran dataset setelah kita drop outliers area
df.shape

fig, axs = plt.subplots(2,3, figsize = (10,5))
plt1 = sns.boxplot(df['price'], ax = axs[0,0])
plt2 = sns.boxplot(df['area'], ax = axs[0,1])
plt3 = sns.boxplot(df['bedrooms'], ax = axs[0,2])
plt1 = sns.boxplot(df['bathrooms'], ax = axs[1,0])
plt2 = sns.boxplot(df['stories'], ax = axs[1,1])
plt3 = sns.boxplot(df['parking'], ax = axs[1,2])

plt.tight_layout()

"""## **Univariate Analysis**"""

numerical_features = ['price', 'area', 'bedrooms', 'bathrooms', 'stories', 'parking']
categorical_features = ['mainroad', 'guestroom', 'basement','hotwaterheating', 'airconditioning','prefarea' ,'furnishingstatus']

df.hist(bins=50, figsize=(20,15))
plt.show()

feature = categorical_features[0]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df1 = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df1)
count.plot(kind='bar', title=feature);

feature = categorical_features[1]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df2 = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df2)
count.plot(kind='bar', title=feature);

feature = categorical_features[2]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df3 = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df3)
count.plot(kind='bar', title=feature);

feature = categorical_features[3]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df4 = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df4)
count.plot(kind='bar', title=feature);

feature = categorical_features[4]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df5 = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df5)
count.plot(kind='bar', title=feature);

feature = categorical_features[5]
count = df[feature].value_counts()
percent = 100*df[feature].value_counts(normalize=True)
df6 = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
print(df6)
count.plot(kind='bar', title=feature);

"""## **Multivariate Analysis**"""

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
    plt.figure(figsize=(15, 5))  # Adjust figure size
    sns.barplot(x=col, y="price", data=df)
    plt.title("Rata-rata 'price' Relatif terhadap - {}".format(col))
    plt.show()

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
    plt.figure(figsize=(15, 5))  # Adjust figure size
    sns.barplot(x=col, y="area", data=df)
    plt.title("Rata-rata 'area' Relatif terhadap - {}".format(col))
    plt.show()

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
    plt.figure(figsize=(15, 5))  # Adjust figure size
    sns.barplot(x=col, y="bedrooms", data=df)
    plt.title("Rata-rata 'bedrooms' Relatif terhadap - {}".format(col))
    plt.show()

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
    plt.figure(figsize=(15, 5))  # Adjust figure size
    sns.barplot(x=col, y="bathrooms", data=df)
    plt.title("Rata-rata 'bathrooms' Relatif terhadap - {}".format(col))
    plt.show()

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
    plt.figure(figsize=(15, 5))  # Adjust figure size
    sns.barplot(x=col, y="stories", data=df)
    plt.title("Rata-rata 'stories' Relatif terhadap - {}".format(col))
    plt.show()

cat_features = df.select_dtypes(include='object').columns.to_list()

for col in cat_features:
    plt.figure(figsize=(15, 5))  # Adjust figure size
    sns.barplot(x=col, y="parking", data=df)
    plt.title("Rata-rata 'parking' Relatif terhadap - {}".format(col))
    plt.show()

sns.pairplot(df)
plt.show()

plt.figure(figsize=(10, 8))
correlation_matrix = df.corr().round(2)

# Untuk menge-print nilai di dalam kotak, gunakan parameter anot=True
sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""## **Data Preparation**
### **Encoding Fitur Kategori**
"""

def binary_map(x):
    return x.map({'yes': 1, "no": 0})

df[categorical_features[0:-1]] = df[categorical_features[0:-1]].apply(binary_map)

df.head()

furnishingstatus = pd.get_dummies(df[categorical_features[-1]])

furnishingstatus.head()

furnishingstatus = furnishingstatus.iloc[:, :-1]

df= pd.concat([df,furnishingstatus], axis = 1)

df.drop(['furnishingstatus'], axis = 1, inplace = True)

df.head()

"""### **Train-Test-Split**"""

from sklearn.model_selection import train_test_split

X = df.drop(["price"],axis =1)
y = df["price"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""### **Standarisasi**"""

from sklearn.preprocessing import StandardScaler

numerical_features = numerical_features[1:]
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

"""## **Model Development**

"""

models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['KNN', 'RandomForest', 'Boosting'])

acc = pd.DataFrame(index=['accuracy'])

from sklearn.neighbors import KNeighborsRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import ShuffleSplit

def grid_search_model(X,y):
    algos = {
        'knn': {
            'model': KNeighborsRegressor(),
            'params': {
                'n_neighbors': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],
            }
        },
        'random_forest': {
            'model': RandomForestRegressor(),
            'params': {
                'n_estimators': [25, 50, 75, 100],
                'max_depth' : [8, 16, 32, 64],
                'random_state': [11, 33, 55, 77],
                'n_jobs' :[1,-1]
            }
        },
        'boosting': {
            'model': AdaBoostRegressor(),
            'params': {
                'learning_rate' : [0.1, 0.05, 0.01, 0.05, 0.001],
                'random_state': [11, 33, 55, 77]
            }
        }

    }

    scores = []
    cv = ShuffleSplit(n_splits=5, test_size=0.05, random_state=123)
    for algo_name, config in algos.items():
        gs =  GridSearchCV(config['model'], config['params'], cv=cv, return_train_score=False)
        gs.fit(X,y)
        scores.append({
            'model': algo_name,
            'best_score': gs.best_score_,
            'best_params': gs.best_params_
        })

    return pd.DataFrame(scores,columns=['model','best_score','best_params'])

grid_search_model(X,y)

"""### **K-Nearest Neighbor**"""

knn = KNeighborsRegressor(n_neighbors=5)
knn.fit(X_train, y_train)

models.loc['train_mse','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

acc.loc['accuracy','knn'] = mean_squared_error(y_pred = knn.predict(X_train), y_true=y_train)

"""### **Random Forest**"""

RF = RandomForestRegressor(n_estimators=100, max_depth=16, random_state=33, n_jobs=1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

acc.loc['accuracy','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""### **Boosting Algorithm**"""

boosting = AdaBoostRegressor(learning_rate=0.1, random_state=11)
boosting.fit(X_train, y_train)

models.loc['train_mse','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)
acc.loc['accuracy','Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""## **Evaluasi Model**"""

acc

X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

mse = pd.DataFrame(columns=['train', 'test'], index=['KNN','RF','Boosting'])

# Dictionary untuk setiap algoritma yang digunakan
model_dict = {'KNN': knn, 'RF': RF, 'Boosting': boosting}

# Mean Squared Error masing-masing algoritma pada data train dan test
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Panggil mse
mse

fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

prediksi = X_test.iloc[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)